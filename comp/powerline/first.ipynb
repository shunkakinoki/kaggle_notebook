{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/kaggle/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import LSTM,Dropout,Dense,TimeDistributed,Conv1D,MaxPooling1D,Flatten\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "from numba import jit\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Both numpy and scipy has utilities for FFT which is an endlessly useful algorithm\n",
    "from numpy.fft import *\n",
    "from scipy import fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FFT to filter out HF components and get main signal profile\n",
    "def low_pass(s, threshold=1e4):\n",
    "    fourier = rfft(s)\n",
    "    frequencies = rfftfreq(s.size, d=2e-2/s.size)\n",
    "    fourier[frequencies > threshold] = 0\n",
    "    return irfft(fourier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Filter out low frequencies from the signal to get HF characteristics\n",
    "def high_pass(s, threshold=1e7):\n",
    "    fourier = rfft(s)\n",
    "    frequencies = rfftfreq(s.size, d=2e-2/s.size)\n",
    "    fourier[frequencies < threshold] = 0\n",
    "    return irfft(fourier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_indices(signal_num):\n",
    "    phase1 = 3*signal_num\n",
    "    phase2 = 3*signal_num + 1\n",
    "    phase3 = 3*signal_num + 2\n",
    "    return phase1,phase2,phase3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/kaggle/lib/python3.6/site-packages/pyarrow/pandas_compat.py:708: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels = getattr(columns, 'labels', None) or [\n",
      "/home/ubuntu/anaconda3/envs/kaggle/lib/python3.6/site-packages/pyarrow/pandas_compat.py:735: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  return pd.MultiIndex(levels=new_levels, labels=labels, names=columns.names)\n",
      "/home/ubuntu/anaconda3/envs/kaggle/lib/python3.6/site-packages/pyarrow/pandas_compat.py:752: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 12.2 s, total: 1min 40s\n",
      "Wall time: 7.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "train_set = pq.read_pandas('../../data/train.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.28 ms, sys: 3.39 ms, total: 10.7 ms\n",
      "Wall time: 9.42 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "meta_train = pd.read_csv('../../data/metadata_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit('float32(float32[:,:], int32)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(x, n_part=1000):\n",
    "    length = len(x)\n",
    "    pool = np.int32(np.ceil(length/n_part))\n",
    "    output = np.zeros((n_part,))\n",
    "    for j, i in enumerate(range(0,length, pool)):\n",
    "        if i+pool < length:\n",
    "            k = x[i:i+pool]\n",
    "        else:\n",
    "            k = x[i:]\n",
    "        output[j] = np.max(k, axis=0) - np.min(k, axis=0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8712/8712 [01:31<00:00, 97.47it/s] \n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "for i in tqdm(meta_train.signal_id):\n",
    "    idx = meta_train.loc[meta_train.signal_id==i, 'signal_id'].values.tolist()\n",
    "    y_train.append(meta_train.loc[meta_train.signal_id==i, 'target'].values)\n",
    "    x_train.append(abs(feature_extractor(train_set.iloc[:, idx].values, n_part=400)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train).reshape(-1,)\n",
    "X_train = np.array(x_train).reshape(-1,x_train[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8712, 400)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lp = []\n",
    "x_train_hp = []\n",
    "x_train_dc = []\n",
    "for i in tqdm(meta_train.signal_id):\n",
    "    idx = meta_train.loc[meta_train.signal_id==i, 'signal_id'].values.tolist()\n",
    "    clear_output(wait=True)\n",
    "    hp = high_pass(train_set.iloc[:, idx[0]])\n",
    "    lp = low_pass(train_set.iloc[:, idx[0]])\n",
    "    meas_id = meta_train.id_measurement[meta_train.signal_id==idx[0]].values[0]\n",
    "    p1,p2,p3=phase_indices(meas_id)\n",
    "    lf_signal_1,lf_signal_2,lf_signal_3 = low_pass(train_set.iloc[:,p1]), low_pass(train_set.iloc[:,p2]), low_pass(train_set.iloc[:,p3])\n",
    "    dc = np.abs(lf_signal_1)+np.abs(lf_signal_2)+np.abs(lf_signal_3)\n",
    "    x_train_lp.append(abs(feature_extractor(lp, n_part=400)))\n",
    "    x_train_hp.append(abs(feature_extractor(hp, n_part=400)))\n",
    "    x_train_dc.append(abs(feature_extractor(dc, n_part=400)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train).reshape(-1,x_train[0].shape[0])\n",
    "x_train_lp = np.array(x_train_lp).reshape(-1,x_train_lp[0].shape[0])\n",
    "x_train_hp = np.array(x_train_hp).reshape(-1,x_train_hp[0].shape[0])\n",
    "x_train_dc = np.array(x_train_dc).reshape(-1,x_train_dc[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train-x_train_lp).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_train.npy', x_train)\n",
    "np.save('x_train_lp.npy', x_train_lp)\n",
    "np.save('x_train_hp.npy', x_train_hp)\n",
    "np.save('x_train_dc.npy', x_train_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "x_train_lp = np.load('x_train_lp.npy')\n",
    "x_train_hp = np.load('x_train_hp.npy')\n",
    "x_train_dc = np.load('x_train_dc.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39024"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_set; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_set = pq.read_pandas('../../data/test.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "meta_test = pd.read_csv('../../data/metadata_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "for i in tqdm(meta_test.signal_id.values):\n",
    "   idx=i-8712\n",
    "   clear_output(wait=True)\n",
    "   x_test.append(abs(feature_extractor(test_set.iloc[:, idx].values, n_part=400)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_lp = []\n",
    "x_test_hp = []\n",
    "x_test_dc = []\n",
    "for i in tqdm(meta_test.signal_id):\n",
    "   idx = idx=i-8712\n",
    "   clear_output(wait=True)\n",
    "   hp = high_pass(test_set.iloc[:, idx])\n",
    "   lp = low_pass(test_set.iloc[:, idx])\n",
    "   meas_id = meta_test.id_measurement[meta_test.signal_id==i].values[0]\n",
    "   p1,p2,p3=phase_indices(meas_id)\n",
    "   lf_signal_1,lf_signal_2,lf_signal_3 = low_pass(test_set.iloc[:,p1-8712]), low_pass(test_set.iloc[:,p2-8712]), low_pass(test_set.iloc[:,p3-8712])\n",
    "   dc = np.abs(lf_signal_1)+np.abs(lf_signal_2)+np.abs(lf_signal_3)\n",
    "   x_test_lp.append(abs(feature_extractor(lp, n_part=400)))\n",
    "   x_test_hp.append(abs(feature_extractor(hp, n_part=400)))\n",
    "   x_test_dc.append(abs(feature_extractor(dc, n_part=400)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(x_test).reshape(-1,x_test[0].shape[0])\n",
    "x_test_lp = np.array(x_test_lp).reshape(-1,x_test_lp[0].shape[0])\n",
    "x_test_hp = np.array(x_test_hp).reshape(-1,x_test_hp[0].shape[0])\n",
    "x_test_dc = np.array(x_test_dc).reshape(-1,x_test_dc[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_set; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.dstack((x_train,x_train_lp,x_train_hp,x_train_dc))\n",
    "test = np.dstack((x_test,x_test_lp,x_test_hp,x_test_dc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_signals = 1 #So far each instance is one signal. We will diversify them in next step\n",
    "n_outputs = 1 #Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose, epochs, batch_size = True, 15, 16\n",
    "n_signals,n_steps, n_length = 4,40, 10\n",
    "train = train.reshape((train.shape[0], n_steps, n_length, n_signals))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_signals)))\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "model.add(TimeDistributed(Dropout(0.5)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras_auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8712/8712 [==============================] - 38s 4ms/step - loss: 0.2403 - keras_auc: 0.5316\n",
      "Epoch 2/15\n",
      "8712/8712 [==============================] - 36s 4ms/step - loss: 0.2287 - keras_auc: 0.5232\n",
      "Epoch 3/15\n",
      "8712/8712 [==============================] - 36s 4ms/step - loss: 0.2014 - keras_auc: 0.5846\n",
      "Epoch 4/15\n",
      "8712/8712 [==============================] - 36s 4ms/step - loss: 0.1782 - keras_auc: 0.6579\n",
      "Epoch 5/15\n",
      "8712/8712 [==============================] - 36s 4ms/step - loss: 0.1633 - keras_auc: 0.7175\n",
      "Epoch 6/15\n",
      "8712/8712 [==============================] - 36s 4ms/step - loss: 0.1533 - keras_auc: 0.7592\n",
      "Epoch 7/15\n",
      "8712/8712 [==============================] - 36s 4ms/step - loss: 0.1463 - keras_auc: 0.7880\n",
      "Epoch 8/15\n",
      "8712/8712 [==============================] - 36s 4ms/step - loss: 0.1417 - keras_auc: 0.8094\n",
      "Epoch 9/15\n",
      "8712/8712 [==============================] - 36s 4ms/step - loss: 0.1369 - keras_auc: 0.8256\n",
      "Epoch 10/15\n",
      "8712/8712 [==============================] - 36s 4ms/step - loss: 0.1270 - keras_auc: 0.8402\n",
      "Epoch 11/15\n",
      "8712/8712 [==============================] - 36s 4ms/step - loss: 0.1289 - keras_auc: 0.8520\n",
      "Epoch 12/15\n",
      "8712/8712 [==============================] - 36s 4ms/step - loss: 0.1260 - keras_auc: 0.8607\n",
      "Epoch 13/15\n",
      "8712/8712 [==============================] - 36s 4ms/step - loss: 0.1281 - keras_auc: 0.8682\n",
      "Epoch 14/15\n",
      "8712/8712 [==============================] - 36s 4ms/step - loss: 0.1232 - keras_auc: 0.8742\n",
      "Epoch 15/15\n",
      "8712/8712 [==============================] - 36s 4ms/step - loss: 0.1238 - keras_auc: 0.8798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f44599206a0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit(train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.reshape((test.shape[0], n_steps, n_length, n_signals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshpreds = (preds>0.5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../../data/sample_submission.csv')\n",
    "sub.target = threshpreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('../../submissions/third_sub.csv',index=False, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
